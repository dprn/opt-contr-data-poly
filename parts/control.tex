\chapter{Controllability}

For this chapter we follow \cite{trelatControl2024}.
% Unless specified otherwise, missing proofs can be found in 

\section{Control systems}

\dfn[]{Control system}{
    A control system in $\bbR^n$ is the differential equation 
    \begin{equation}
        \label{eq:cs-edo}
        \dot x = f(t,x,u),
    \end{equation}
    where
    \begin{itemize}
        \item The \emph{state} is a the function $x: \bbR \to \bbR^n$;
        \item $f:\bbR\times \bbR^n \times \bbR^m \to \bbR^n$ is  of class $C^1$ w.r.t.~$(x,u)\in \bbR^n\times \bbR^m$, and locally integrable w.r.t.~$t\in \bbR$;
        \item The \emph{control} $u:\bbR \times U$ is a measurable and essentially bounded function of time, taking values in $U\subset \bbR^m$.
    \end{itemize}

    The control system is 
    \begin{itemize}
        \item \emph{Linear} is $f(t,x,u) = A(t)x + B(t)u+r(t)$ for $A:\bbR\to \bbR^{n\times n}$, $B:\bbR\to \bbR^{n\times m}$, $r:\bbR\to \bbR^n$. In this case, we assume these functions to be of class $L^\infty$ on every compact interval.
        \item \emph{Autonomous} if $f(t,x,u)=f(x,u)$ is independent of time. Otherwise, the system is \emph{instationary} or \emph{time-varying}.
    \end{itemize}
}

Once a control $u$ and an initial condition $x_0\in\bbR^n$ are fixed, the existence and uniqueness of solutions to the non-autonomous equation \eqref{eq:cs-edo} is guaranteed by the following.

\thm[]{CarathÃ©odory Existence Theorem}{
    Consider the Cauchy problem 
    \begin{equation}
        \label{eq:cauchy-prob}
        \begin{cases}
            \dot x = f(t,x),\\
            x(0)=x_0\in \bbR^n.
        \end{cases}
    \end{equation}
    Assume that $f:\bbR\times \bbR^n\to \bbR^n$ satisfies the following conditions
    \begin{itemize}
        \item $f(t,\cdot)$ is Lipschitz continuous for any $t\in \bbR$ with Lispchitz constant $L(t)$ that is locally integrable;
        \item $f(\cdot,x)$ is measurable for any $x\in \bbR^n$;
        \item there exists $r,M>0$ such that $\|f(t,x)\|_2\le M$ for any $(t,x)\in (-r,r) \times B(0,r)$.
    \end{itemize}
    Then, there exists a unique solution to \eqref{eq:cauchy-prob}, maximally defined on some open interval $I\subset\bbR$ such that $0\in \bbR$.
}

When considering the control system on an interval $[0,T]$, we need its solutions to not blow up before the time $T$. 

\dfn[]{Admissible controls}{
    Let $x_0\in \bbR^n$ and $T>0$. A control $u\in L^\infty([0,T],U)$ is \emph{admissible} on $[0,T]$ at $x_0$ if the associated trajectory $x_u$ of \eqref{eq:cs-edo} such that $x_u(0)=x_0$ is well-defined on $[0,T]$.
    We let 
    \begin{equation}
        \mcU_{x_0,T} = \{ u\in L^\infty([0,T],U) \mid u \text{ is admissible} \}.
    \end{equation}
}

\dfn[]{Controllability}{
    The \emph{end-point mapping} $\End_{x_0,T}$ is defined by
    \begin{equation}
        \End_{x_0,T} :\mcU_{x_0,T}\to \bbR^n ,\qquad 
        \End_{x_0,T}(u) = x_u(T).
    \end{equation}
    The \emph{reachable (or accessible) set} from $x_0$ in time $T>0$ is
    \begin{eqnarray}
        \reach_{x_0,T} =\End_{x_0,T}(\mcU_{x_0,T}) .
    \end{eqnarray}

    The system \eqref{eq:cs-edo} is
    \begin{itemize}
        \item \emph{Globally controllable} from $x_0$ in time $T>0$ if $\End_{x_0,T}$ is surjective, that is,
              \begin{equation}
                  \reach_{x_0,T}= \bbR^n.
              \end{equation}
        \item \emph{Locally controllable} from $x_0$ in time $T>0$ around $x_1\in \reach_{x_0,T}$ if $x_1$ is in the interior of $\reach_{x_0,T}$. That is, if $\End_{x_0,T}$ is locally surjective near $x_1$.
    \end{itemize}
}

\ex[trivial-control]{Trivial control system}{
    Consider the control system, for $x\in \bbR^d$,
    \begin{equation}
        \dot x= u, \qquad u\in L^\infty([0,T],\bbR^d).
    \end{equation}
    Then,
    \begin{equation}
        \End_{x_0,T}(u) = x_0 + \int_0^T u(s)\, ds.
    \end{equation}
    In particular, the system is globally controllable from any $x_0\in \bbR^d$ and in any time $T>0$.
    Indeed, for any $x_1\in \bbR^d$, the constant control 
    \begin{equation}
        u(t) = \frac{x_1 - x_0}{T}, \qquad t\in [0,T],
    \end{equation}
    steers the system from $x_0$ to $x_1$ in time $T$.
}

\ex[]{Not globally controllable system}{
    Consider the control system, for $x\in \bbR$,
    \begin{equation}
        \label{eq:not-globally-contr}
        \dot x = u, \qquad u\in L^\infty([0,T],[0,+\infty)).
    \end{equation}
    Since $\dot x \ge 0$, the system cannot be globally controllable from $x_0\in \bbR$ in any time $T>0$.
    Indeed, proceeding as in Example~\ref{ex:trivial-control} one shows that 
    \begin{equation}
        \reach_{x_0,T}=[x_0,+\infty), \qquad \forall x_0\in\bbR,\,  T>0.
    \end{equation}
    In particular, the system is locally controllable around any $x_1>x_0$.
}

% \ex[]{Not globally controllable system}{
%     Consider the control system, for $x\in \bbR$,
%     \begin{equation}
%         \label{eq:not-globally-contr}
%         \dot x = |x| + u, \qquad u\in L^\infty([0,T],[-1,1]),
%     \end{equation}
%     with initial condition $x_0=0$.
%     Let us show that 
%     \begin{equation}
%         \reach_{0,T} =(-1,+\infty) \qquad  \forall T>0,
%     \end{equation}
%     In particular, the system is not globally controllable from $0$ in any time $T>0$. 
    
%     We start by claiming that $x(t)> -1$ for any $t\ge 0$. 
%     To see this, assume by contradiction that
%     \begin{equation}
%         t_1 := \inf\{ t\ge 0 \mid x(t)<-1\} < +\infty.
%     \end{equation}
%     In particular, by continuity of $x$, there exists $\varepsilon>0$ such that $x(t)<0$ for $t\in [t_1,t_1+\varepsilon]$.
%     Letting 
%     \begin{equation}
%         t_2 := \sup\{t\in [0,t_1]\mid x(s)<0, \, \forall s\in [t,t_1]\},
%     \end{equation}
%     we then have that $x(t)\in[-1,0]$ for $t \in [t_2,t_1+\varepsilon]$, and $x(t_2)=0$. This implies $\dot x \ge -x + 1$ on $[t_2,t_1+\varepsilon]$, and thus
%     \begin{equation}
%         x(t) \ge -1 + e^{-(t-t_2)} > -1 \qquad \forall s\in [t_2,t_1+\varepsilon].
%     \end{equation}
%     This contradicts the definition of $t_1$, and thus proves that $\reach_{0,T} \subset (-1,+\infty)$.

%     To show the converse inclusion, let us exhibit a control steering the system from $x_0=0$ to $x_1$ in time $T>0$.
% }

\section{Controllability of linear autonomous systems}

In this section we consider the linear autonomous control system
\begin{equation}
    \label{eq:cs-linear}
    \dot x = Ax + Bu.
\end{equation}
It is possible to show that there is no blow-up in finite time for linear systems, and thus $\mcU_{x_0,T} = L^\infty([0,T], U)$.

An essential tool for the study of these systems is the variation of constants formula (or Duhamel formula) for its solutions:
\begin{equation}
    \label{eq:duhamel-formula}
    x_u(t) = e^{tA}x_0 + \int_0^t e^{(t-s)A}Bu(s)\, ds, 
    \qquad \forall t\in [0,T], \,  u\in L^\infty([0,T], U).
\end{equation}

We also need to recall the following celebrated result.

\thm[cayley-hamilton]{Cayley-Hamilton Theorem}{
    Let $A\in \bbR^{n\times n}$ be a matrix with characteristic polynomial 
    \begin{equation}
        \chi_A(z) = \det(z\idty - A) = z^n + a_1 z^{n-1}+\ldots +a_{n-1}z + a_n.
    \end{equation}
    Then, letting $p_A(A)$ be the number obtained by replacing the unknown $z$ with the matrix $A$ in this expression, we have $p_A(A)=0$. 
    That it,
    \begin{equation}
        A^n + a_1 A^{n-1} + \ldots + a_{n-1} A + a_n =0.
    \end{equation}
}

In the case of linear systems, it turns out that controllability can be verified via a purely algebraic condition.

\dfn[]{Kalman rank condition}{
    We say that the pair $(A,B)\in \bbR^{n\times n}\times \bbR^{n\times m}$ satisfies the \emph{Kalman rank condition} if the Kalman matrix 
    \begin{eqnarray}
        K=[ B, AB, \ldots, A^{n-1}B] \in \bbR^{  n \times nm},
    \end{eqnarray}
    is of maximal rank $n$.
}

\thm[kalman-thm]{Kalman Theorem}{
    Assume that $U=\bbR^n$. Then, \eqref{eq:cs-linear} is controllable from $x_0\in\bbR^n$ and in time $T>0$ if and only if $(A,B)$ satisfies the Kalman rank condition.

    In particular, if a linear system is controllable from $x_0$ in time $T>0$, then it is controllable from any initial point and in any time.
}

\begin{proof}
    By the variation of constants formula \eqref{eq:duhamel-formula}, we see that controllability is equivalent to the surjectivity of the linear operator 
    \begin{equation}
        \label{eq:Lu}
        L : L^\infty([0,T],\bbR^m) \to \bbR^n, 
        \qquad 
        Lu =\int_0^T e^{-As}Bu(s)\, ds .
    \end{equation}
    Here, we used that the exponential matrix $e^{TA}$ is always invertible.

    Let us prove that the fact that $L$ invertible implies $\rank K=n$. We proceed by contradiction and assume that $\rank K<n$. That is, there exists $p\in \bbR^n$, $p\neq 0$, such that 
    \begin{equation}
        \label{eq:AiB}
        p^\top K = 0 
        \iff
        p^\top A^i B = 0, \qquad \forall i\in \llbracket 1,n\rrbracket.
    \end{equation}
    Recall that by Cayley-Hamilton Theorem, we can write $A^j$ as a linear combination of $\idty, A,\ldots, A^{n-1}$. That is, for any $j\in\bbN$, there exists $a_{0},\ldots, a_{n-1}$ such that
    \begin{equation}
        A^j = \sum_{i=0}^{n-1}a_i A^i.
    \end{equation}
    This implies that \eqref{eq:AiB} actually holds for any $i\in \bbN$, which yields
    \begin{equation}
        p^\top e^{-As}B =  \sum_{j=0}^{+\infty} p^\top \frac{(-As)^j}{j!}B = 0.
    \end{equation}
    In particular, this shows that $p^\top Lu=0$ for any $u\in L^\infty([0,T],\bbR^m)$ proving that $L$ is not surjective.

    To prove the opposite implication, assume that there exists $p\in \bbR^n$, $p\neq0$, such that 
    \begin{equation}
        \label{eq:pLu}
        p^\top Lu=0\qquad \forall u\in L^\infty([0,T],\bbR^m). 
    \end{equation}
    Consider, for $i\in \llbracket 1,n\rrbracket$ and $\tau\in [0,T]$, the control 
    \begin{equation}
        u(\tau) = 
        \begin{cases}
            e_i, & \text{ if } t\in[0,\tau],\\
            0 & \text{ otherwise.}
        \end{cases}
    \end{equation}
    Here, $e_i$ is the $i$-th element of the canonical basis of $\bbR^n$. Thus, we have
    \begin{equation}
        Lu = \int_0^\tau e^{-As}Bu\,ds = \left[\frac{\idty - e^{-\tau A}}{A}\right] B u, \qquad
        \text{where}\qquad 
        \frac{\idty - e^{-\tau A}}{A} = \sum_{j=1}^{+\infty} \frac{(-1)^{j-1}\tau^j}{j!}A^{j-1}.
    \end{equation}
    Assumption \eqref{eq:pLu} then yields 
    \begin{equation}
       0 = p^\top\left[\frac{\idty - e^{-\tau A}}{A}\right]Bu = \sum_{j=1}^{+\infty} \frac{(-1)^{j-1}\tau^j}{j!}p^{\top}A^{j-1}Bu , 
       \qquad \forall \tau\in [0,T].
    \end{equation}
    By analyticity\footnote{Equivalently, one can observe that $$0=\frac{d^k}{d\tau^k}\left[\sum_{j=1}^{+\infty} \frac{(-1)^{j-1}\tau^j}{j!}p^{\top}A^{j-1}Bu\right]_{\tau =0} = p^\top A^{k-1}Bu, \qquad \forall k\in\bbN.$$} w.r.t.~$\tau$ of the right-hand side, this implies that $p^\top A^{j-1}Bu=0$, that is $\rank K<n$.
\end{proof}

\cor[local-contr-with-control-constraint]{Controllability with control constraints}{
    Assume that $0\in \Int(U)$, and that the Kalman condition holds true. Then, the control system is locally controllable around $e^{TA}x_0$ for any $x_0\in \bbR^n$ and any $T>0$. Namely,
    \begin{equation}
        e^{TA}x_0\in \Int\reach(x_0,T) .
    \end{equation}
}

\begin{proof}
    By the variation of constant formula \eqref{eq:duhamel-formula}, we have (for the unconstrained system)
    \begin{equation}
        \End_{x_0,T}(u) = e^{TA}x_0 + Lu,
    \end{equation}
    where $L$ is the operator defined in \eqref{eq:Lu}. 
    Observe that $L$ is a continuous linear map, since 
    \begin{equation}
        \|Lu\|_2 \le T \max_{s\in [0,T]} \|e^{-As}B\| \, \|u\|_\infty.
    \end{equation}
    In particular, $L$ is an open mapping and hence for any neighborhood $V\subset U$ of the origin, we have that $\End_{x_0,T}(V)$ is a neighborhood of $\End_{x_0,T}(0)= e^{TA}x_0\in\reach(x_0,T)$.
\end{proof}


\thm[]{Hautus Test}{
    The following assertions are equivalent 
    \begin{enumerate}
        \item The pair $(A,B)$ satisfies the Kalman rank condition.
        \item $\rank [\lambda\idty - A, B] = n$ for any $\lambda\in \bbC$.
        \item $\rank [\lambda\idty - A, B] = n$ for any $\lambda\in \Spec A$.
        \item For any eigenvector $z$ of $A^\top$, we have $B^\top z \neq 0$.
        \item There exists $c>0$ such that 
        \begin{equation}
            \label{eq:lambda-c}
            \|(\lambda\idty - A^\top) z \|_2^2 + \|B^\top z\|_2^2 \ge c\|z\|_2^2, 
            \qquad
            \forall z\in \bbR^n,\, 
            \forall \lambda\in \bbC.
        \end{equation}
    \end{enumerate}
}

\begin{proof}
    We start by showing the equivalence of assertions 2 to 5.

    \emph{$2\iff 3$} Since $\Spec A \subset \bbC$, we have that assertion 2 implies assertion 3.
    On the other hand, if assertion 3 holds we obtain assertion 2 by recalling that $\lambda\idty - A$ is invertible for any $\lambda \in \bbC\setminus \Spec A$.


    \emph{$3\iff 4$}
    If assertion 4 does not hold for an eigenvector $z$ associated to $\lambda\in \Spec A$, we clearly have $z^\top (\lambda\idty - A)  =z^\top B=0$, which contradicts assertion 3. A similar reasoning shows the opposite implication.

    \emph{$2\iff 5$} If assertion 2 does not hold, we contradict assertion 5 as above. To prove the other implication, let
    \begin{equation}
        M_\lambda = (\bar \lambda\idty - A)(\lambda \idty - A^\top ) + BB^\top.
    \end{equation}
    The matrix $M_\lambda$ is symmetric and it holds
    \begin{equation}
        \label{eq:lambda-c}
        \|(\lambda\idty - A^\top) z \|_2^2 + \|B^\top z\|_2^2 \ge z^\top M_\lambda z
        \qquad
        \forall z\in \bbR^n.
    \end{equation}
    Hence, letting $\mu(\lambda)$ be the smallest eigenvalue of $M_\lambda$, we have assertion 5 with $c = \inf_{\lambda \in \bbC} \mu(\lambda)$. We have that $c>0$ since $\lambda\mapsto \mu(\lambda)$ is continuous and $\mu(\lambda) \rightarrow + \infty$ as $|\lambda|\to +\infty$.

    \emph{$1\iff 4$}
    We are left to showing that assertion 1 is equivalent to the other equivalent assertions. 
    It is immediate to observe that if assertion 4 does not hold, the same is true for assertion 1. 
    To show the opposite implication,  set
    \begin{equation}
        N = \{ z\in\bbR^n\mid z^\top A^k B = 0\, \forall k\in \bbN\}.
    \end{equation}
    In particular, $N = \{0\}$ if and only if $(A,B)$ satisfies the Kalman rank condition. Assume this is not the case. Then, since $N$ is non-trivial $A^\top$ invariant (i.e., $A^\top N \subset N$) subspace, we have that $A^\top$ has at least one non-zero eigenvalue $z\in N\setminus\{0\}$. But then, $B^\top z=0$ by definition of $N$, contradicting assertion 4.
\end{proof}

\subsection{Similar systems and normal forms}

In this section we look at what happens if we perform a change of basis $x_2 = Px_1$ for some $P\in \operatorname{GL}_2(\bbR)$.

\dfn{Similar systems}{
    The linear control systems 
    \begin{equation}
        \dot x_1 = A_1x_1 + B_1 u_1
        \qquad\text{and}\qquad
        \dot x_2 = A_2x_2 + B_2 u_2,
    \end{equation}
    are \emph{similar} if there exists $P\in \operatorname{GL}_2(\bbR)$ such that $A_2= PA_1P^{-1}$ and $B_2 = PB_1$. 
    In this case we say that the pairs $(A_1,B_1)$ and $(A_2,B_2)$ are similar.
}

Observe that the Kalman property is intrinsic, i.e., is invariant under the similarity transformation $P$.
Indeed, letting $K_1$ and $K_2$ be the Kalman matrices associated to two similar systems, we have $K_2=PK_1$.

An important application of similar systems is the existence of various normal forms, i.e., a change of coordinates (and sometimes a change of inputs) that transforms a nonlinear or linear control system into a simpler, standardized structure, where its controllability, observability, or stabilization properties become explicit.

The following result goes in that direction, and can be seen as an extension of Kalaman Theorem (Theorem~\ref{th:kalman-thm}) to non-controllable systems.

\prop[]{}{
    Consider a linear system \eqref{eq:cs-linear} whose Kalman matrix $K$ satisfies $\rank K = r$. Then, letting $y=(y_1,y_2)^\top\in \bbR^{r\times (n-r)}$, the system is similar to 
    \begin{eqnarray}
        \dot y_1 &=& A_1' y_1 + B_1 u + A_3' y_2 \\
        \dot y_2 &=& A'_2 y_2.
    \end{eqnarray}
    In particular, this splits the original system in a controllable part (the variable $y_1$) and an uncontrollable one (the variable $y_2$).
}

\begin{proof}
    Let us assume that $\rank K < n$, otherwise there is nothing to prove.
    Consider the subspace $F=\operatorname{Ran} K$, and observe that it holds 
    \begin{equation}
        F =\operatorname{Ran} B + \operatorname{Ran} AB + \ldots +\operatorname{Ran} A^{n-1}B.
    \end{equation}
    Then, $\dim F=r$ and, using the Cayley-Hamilton Theorem is straightforward to verify that $F$ is invariant under $A$ (i.e., $AF\subset F$).
    Hence, $\bbR^n = F\oplus G$ for some subspace $G$ such that $\dim G=n-r$.
    Pick   a basis $(f_1,\ldots, f_r)$ of $F$, and a basis $(f_{r+1},\ldots, f_n)$ of $G$, and let $P$ be the matrix encoding the change of basis from $(f_1,\ldots, f_n)$ to the canonical basis of $\bbR^n$.

    Using the invariance of $F$ w.r.t.~$A$, we obtain that 
    \begin{equation}
        A' = PAP^{-1} =
        \begin{pmatrix}
            A_1' & A_3' \\ 
            0 & A_2'
        \end{pmatrix},
    \end{equation}
    where $A_1'\in \bbR^{r\times r}$. Moreover, since $\operatorname{Ran} B \subset F$, we have that 
    \begin{equation}
        B' = P B = 
        \begin{pmatrix}
            B_1'\\0
        \end{pmatrix}.
    \end{equation}
\end{proof}

\thm[brunovski-single-input]{Brunovski normal form, single-input case}{
    Consider the linear system \eqref{eq:cs-linear} with scalar input (i.e., $m=1$ so that $B\in \bbR^{n\times 1}$), and assume that $(A,B)$ satisfies the Kalman rank condition.
    Then, letting the characteristic polynomial of $A$ be 
    \begin{equation}
        \chi_A(z) = \det(z\idty - A) = z^n + a_1 z^{n-1} + \ldots + a_{n-1}z + a_n,
    \end{equation}
    the control system is similar to the following chained form 
    \begin{equation}
        \begin{cases}
            \dot x_1 = x_2 \\
            \quad \vdots \\
            \dot x_{n-1} = x_n \\
            \dot x_n = -a_n x_1 - a_{n-1} x_2 -\cdots -a_1 x_n + u.
        \end{cases}
    \end{equation}
}

\begin{proof}
    It suffices to show that the pair $(A,B)$ is similar to $(\tilde A, \tilde B)$ given by 
    \begin{equation}
        \tilde A = 
        \begin{pmatrix}
            0 & 1 &  \cdots & 0 \\
            \vdots & \ddots & \ddots & \vdots \\
            0 & \cdots &  0 & 1 \\
            -a_n & -a_{n-1} &  \cdots & -a_1 
        \end{pmatrix}
        \qquad\text{and}\qquad
        \tilde B = 
        \begin{pmatrix}
            0\\ \vdots \\ 0 \\ 1
        \end{pmatrix}.
    \end{equation} 
    
    Let us define the vectors 
    \begin{equation}
        v_n = B, \, v_{n-1} = A B,\, \ldots ,\, v_1 = A^{n-1}B.
    \end{equation}
    These form a basis, since the Kalman matrix $K = [v_n,\ldots, v_1]$ is full rank. 
    By definition of $v_n$ it is immediate to observe that $B$ transforms to $\tilde B$ under the change of basis defined by $\{v_1,\ldots,v_n\}$.

    Let us check that this is true also for $\tilde A$ with respect to $A$.
    By definition, it trivially holds that 
    \begin{equation}
        A v_{j} = A \left(A^{n-j}B\right) = A^{n-(j-1)}B =  v_{j-1}, \qquad \forall j\in \llbracket 2,n\rrbracket.
    \end{equation}
    In other words, in the basis $\{v_1,\ldots, v_n\}$ the matrix $A$ acts as $\tilde A$ on the last $n-1$ coordinates.
    To compute $A v_1$, we apply Cayley-Hamilton Theorem (Theorem~\ref{th:cayley-hamilton}) to obtain
    \begin{equation}
        A v_1 = A^n B = (-a_{1}A^{n-1}- \ldots - a_{n-1}A-a_n)B = -a_1 v_1 - \ldots -a_n v_n.
    \end{equation}
    This shows that indeed $\tilde A$ corresponds to the matrix $A$ under the change of basis $\{v_1,\ldots,v_n\}$. 
\end{proof}

In the general case $m > 1$, the system decomposes into $m$ \emph{controllability chains} (also called \emph{Jordan chains of the couple} $(A,B)$).
This, however, requires to perform also a linear change of input.
More precisely, we have the following.

\thm[]{Brunovski normal form, general case}{
    Consider the linear system \eqref{eq:cs-linear} and assume that $(A,B)$ satisfies the Kalman rank condition.
    Then there exist invertible matrices
    $P \in \mathbb{R}^{n \times n}$ (change of state coordinates)
    and $R \in \mathbb{R}^{m \times m}$ (change of input coordinates)
    such that, under the transformations
    \[
        x = P \tilde x,
        \qquad
        u = R \tilde u,
    \]
    the system becomes
    \[
        \dot{\tilde x} = A_c \tilde x + B_c \tilde u,
        \qquad\text{with}\qquad
        A_c = T^{-1} A T,
        \qquad
        B_c = T^{-1} B R.
    \]
    Here $(A_c,B_c)$ has the block-diagonal \emph{BrunovskÃ½ form}
    \[
        A_c =
        \begin{bmatrix}
            A_1    & 0      & \cdots & 0      \\
            0      & A_2    & \cdots & 0      \\
            \vdots & \vdots & \ddots & \vdots \\
            0      & 0      & \cdots & A_m
        \end{bmatrix},
        \qquad
        B_c =
        \begin{bmatrix}
            B_1    & 0      & \cdots & 0      \\
            0      & B_2    & \cdots & 0      \\
            \vdots & \vdots & \ddots & \vdots \\
            0      & 0      & \cdots & B_m
        \end{bmatrix},
    \]
    where each block $(A_i,B_i)$ is a single-input BrunovskÃ½ block of size $r_i$, as in Theorem~\ref{th:brunovski-single-input}.
    The integers $r_1,\dots,r_m$ are the \emph{controllability indices} of $(A,B)$ and satisfy
    \[
        r_1 + \cdots + r_m = n.
    \]
}

\section{Controllability of time-varying linear systems}

We now turn to time-varying control systems 
\begin{equation}
    \label{eq:cs-linear-time-var}
    \dot x = A(t)x + B(t)u,
\end{equation}
where $A:\bbR \to \bbR^{n\times n}$ and $B:\bbR\to \bbR^{n\times m}$.

\dfn[]{State-transition matrix}{
    The \emph{state-transition matrix} $R:\bbR\times\bbR \to \bbR^{n\times n}$ of sytem $\dot x = A(t)x$ is the unique solution of 
    \begin{equation}
        \frac{\partial}{\partial t} R(t,s) = A(t) R(t,s), \qquad R(s,s) = \idty.
    \end{equation}
}

We have the following standard result.

\prop[state-transition-matrix]{}{
    Let $R$ be the state-transition matrix of $\dot x = A(t)x$. We have
    \begin{itemize}
        \item In the autonomous case (i.e., $A(t)\equiv A$), we have $R(t,s) = e^{(t-s)A}$.
        \item Semigroup property: It holds 
        \begin{equation}
            R(t,s)R(s,\tau) = R(t,\tau) \qquad \forall t,s,\tau\in\bbR.
        \end{equation}
        In particular, $R(t,s)^{-1}=R(s,t)$.
        \item Solutions to \eqref{eq:cs-linear-time-var}: For any $x_0\in \bbR^n$, $T>0$, and $u\in \mathcal U_{x_0,T}$, we have 
        \begin{equation}
            x(t) = R(t,0)x_0 + \int_0^t R(t,s)Bu(s)\, ds.
        \end{equation}
    \end{itemize}
}

Due to the time-varying nature of the system, a reasonable generalization of Kalman rank condition would be that the Kalman matrix $K(t)$ of $(A(t),B(t))$ be full rank at each time $t>0$. 
This is however too strong, as the following shows.

\ex[]{}{
    Consider the time-varying linear system with $n=2$ and $m=1$:
    \begin{equation}
        \dot x = B(t)u(t), \qquad
        B(t) =
        \begin{cases}
             (1,0)^\top 
             & \text{ if } t\in [0,1], \\
             (0,1)^\top
             & \text{ if } t>1.
        \end{cases}
    \end{equation}
    Since $A(t)=0$ for all times, the instananeous Kalman matrix $K(t)$ is not full-rank. However, it is straightforward to explicitly show that $\reach(x_0,T)=\bbR^2$ for all $T>1$.
}

Indeed, in the time-varying case, the instantaneous lack of controllability for certain directions at a time $t_0$ is not an issue if at later times these directions are controllable. To formalize this idea, we introduce the following.

\dfn[]{Controllability Gramian}{
    The \emph{Gramian matrix} of system \eqref{eq:cs-linear-time-var} at time $T>0$ is the matrix
    \begin{equation}
        G_T := \int_0^T R(T,t)B(t)B(t)^\top R(T,t)^\top \, dt \in \bbR^{n\times n}.
    \end{equation}
}

Before proving the controllability theorem, let us make the following observation.

\prop[gram-matrix-observability]{Observability inequality}{
    Let $T>0$. The Gramian matrix is a symmetric non-negative matrix, whose invertibility is equivalent to the following \emph{observability inequality}: There exists $C_T>0$ such that
    \begin{equation}
        \label{eq:observability}
        \int_0^T \|B(t)^\top R(T,t)^\top \psi\|_2^2 \, dt \ge C_T \|\psi\|_2^2
        \qquad \forall \psi\in\bbR^n.
    \end{equation}
}

\begin{proof}
    The symmetry of $G_T$ is immediate from the definition. Moreover,
    \begin{equation}
        \psi^\top G_T \psi = \int_0^T \psi^\top R(T,t)B(t) B(t)^\top R(T,t)^\top \psi\, dt = \int_0^T \|B(t)^\top R(T,t)^\top \psi\|_2^2 \, dt \ge 0.
    \end{equation}
    This proves both the non-negativity and the equivalence between the invertibility of $G_T$ and \eqref{eq:observability}.
\end{proof}

\begin{remark}
    Inequality \eqref{eq:observability} is called an observability inequality for the following reason. Consider the \emph{adjoint system} to \eqref{eq:cs-linear-time-var}, which is
    \begin{equation}
        \dot z = -A(t)^\top  z, \qquad z(T) = \psi,
    \end{equation}
    and assume that the output $y(t) = B(t)^\top z(t)$ is measured.
    In particular, the energy of this output over $[0,T]$ is the quantity
    \begin{equation}
        E(T) = \int_0^T \|y(t)\|_2^2\, dt.
    \end{equation}
    But, since $y(t) = B(t)^\top R(T,t)^\top \psi$, this coincide with the left-hand side of \eqref{eq:observability}, which can then be recast as
    \begin{equation}
        \int_0^T \|y(t)\|_2^2 \, dt \ge C_T \|z(T)\|_2^2.
    \end{equation}
    Namely, the output $y(t)$ controls the size of the final state $z(T)$.
    In particular, if $y(t)\neq 0$ for all $t\in [0,T]$ we are sure that $z(T)=0$.
    More generally, one can show that this inequality allows to reconstruct the state $z(T)$ from the measurements $y:[0,T]\to \bbR$.
% 
    This property is called \emph{observability of the adjoint system}. 
\end{remark}

The following theorem shows that the observability property introduced above is actually equivalent to the controllability of the original system.

\thm[]{}{
    Assume that $U=\bbR^m$. Then, the control system \eqref{eq:cs-linear-time-var} is controllable from $x_0\in \bbR^n$ in time $T>0$ if and only if the Gramian matrix $G_T$ is invertible.
    In particular, if a linear time-varying system is controllable from $x_0$ in times $T>0$, then it is controllable for any time $T'>T$ and from any initial point.
}

\begin{proof}
    By Proposition~\ref{prop:state-transition-matrix}, given a control $u$ we have that
    \begin{equation}
        \label{eq:end-point-formula}
        \End_{x_0,T}(u) = x_u(T) = x^\star + Lu,
        \qquad \text{where}\qquad
        x^\star = R(T,0)x_0,
        \quad\text{and}\quad
        Lu = \int_0^T R(T,t)B(t)u(t)\, dt
    \end{equation}


    Assume that $G_T$ be invertible and let us prove that $\End_{x_0,T}$ is surjective (i.e., that the system is controllable).
    Fix $x_1\in \bbR^n$ and let us construct a control $u$  of the form $u(t) = B(t)^\top R(t,T)^\top \psi$ for some $\psi\in \bbR^n$ such that $\End_{x_0,T}(u)=x_1$.
    Since this choice of $u$ implies that $Lu = G_T\psi$, we have
    \begin{equation}
        \End_{x_0,T}(u) = x^\star + G_T \psi.
    \end{equation}
    By invertibility of $G_T$ it then suffices to choose $\psi = G^{-1}_T (x_1-x^\star)$.

    Conversely, let us assume that $G_T$ is not invertible. By Proposition~\ref{prop:gram-matrix-observability} we then have that there exists $\psi\in \bbR^n$, $\psi\neq 0$, such that
    \begin{equation}
        \int_0^T \|B(t)^\top R(T,t)^\top \psi\|_2^2 \, dt = 0
        \implies
        B(t)^\top R(T,t)^\top \psi = 0 \qquad \text{for a.e.\ } t\in [0,T].
    \end{equation}
    It follows that
    \begin{equation}
        \psi^\top Lu = 0,
        \qquad \forall u\in L^\infty([0,T],\bbR^m),
    \end{equation}
    where $L$ is defined in \eqref{eq:end-point-formula}.
    Hence,
    \begin{equation}
        \psi^\top \End_{x_0,T}(u) = \psi^\top (x^\star + Lu) = \psi^\top x^\star, \qquad \forall u \in L^\infty([0,T],\bbR^m).
    \end{equation}
    In particular, the range of $\End_{x_0,T}$ is contained in a proper affine subspace of $\bbR^n$:
    \begin{equation}
        \operatorname{ran}\End_{x_0,T} \subset \{ z \in \bbR^n\mid \psi^\top (z-x^\star) = 0\}.
    \end{equation}
    This contradicts the surjectivity of $\End_{x_0,T}$.
\end{proof}

The same argument used to derive Corollary~\ref{th:local-contr-with-control-constraint} can be used to derive the following.

\cor[]{Controllability with control constraints}{
    Assume that $0\in \operatorname{int}(U)$ and that the Gramian matrix $G_T$ is invertible for some $T>0$. 
    Then, the control system is locally controllable around $x_0\in \bbR^n$ in time $T>0$.
}


We conclude this section by stating a proper generalization of the Kalman rank condition to the time-varying case.

\thm[Time-varying Kalman theorem]{}{
    Consider \eqref{eq:cs-linear-time-var} with $U=\bbR^m$ and such that $t\mapsto A(t)$ and $t\mapsto B(t)$ are of class $C^\infty$.
    Define the sequence of matrices 
    \begin{equation}
        B_0(t) = B(t),
        \qquad 
        B_{j+1} = A(t)B_j(t) - \frac{d}{dt}B_j(t), \qquad j\in \bbN.
    \end{equation}
    Then, the system is controllable if there exists $t_0\in [0,T]$ such that 
    \begin{equation}
        \bigcup_{j\in \bbN} \operatorname{ran} B_j(t_0)= \bbR^n.
    \end{equation}
    If, moreover, $t\mapsto A(t)$ and $t\mapsto B(t)$ are analytic, then the above property is equivalent to controllability and independent of $t_0\in [0,T]$.
}


\chapter{Optimal control theory for linear systems}

Given a control system 
\begin{equation}
    \dot x = f(t,x,u), \qquad x(0)=x_0,
\end{equation}
that is controllable at $x_1$ in a certain time $T>0$, it is natural to wonder which control $u\in \mathcal U_{x_0,T}$ is the ``best'' to reach $x_1$.
To answer this question, we need to introduce a cost functional $J:\mathcal U_{x_0,T} \to \bbR$, and then look for a control $u^\star$ minimizing $J$ among all controls that steer $x_0$ to $x_1$ in time $T$.
This is the goal of optimal control theory.

\dfn[]{Optimal control problem}{
Given $x_0\in\bbR^d$, $T>0$, and $x_1\in \reach_{x_0,T}$, the \emph{optimal control problem} associated with a cost functional $J:\mathcal U_{x_0,T}\to \bbR$ is
\begin{equation}
    \label{eq:ocp}
    \begin{cases}
        \dot x = f(t,x,u) \\
        x(0)=x_0 \\
        x(T) = x_1 \\
        J(u) \rightarrow \min.
    \end{cases}
\end{equation}
}
Many variants of this problem exist, e.g., where the initial or final positions are not fixed but belong to a certain subset of the state space, or where the final time is free.

\dfn[]{Admissible controls for \eqref{eq:ocp}}{
The set of \emph{admissible controls} to \eqref{eq:ocp} is 
\begin{equation}
    \Omega_{x_0,x_1,T} = \{ u\in \mathcal U_{x_0,T}\mid x_u(T) = x_1 \}.
\end{equation}
}
Then, \eqref{eq:ocp} can be recast as an (infinite-dimensional) optimization problem under constraints. Namely,
\begin{equation}
    \min_{u\in \Omega_{x_0,x_1,T}} J(u).
\end{equation}

\section{Linear-quadratic optimal control problems}

In this chapter, we follow \cite{jurdjevicGeometric1997}, and we only consider linear autonomous control systems of the form \eqref{eq:cs-linear}.
For this kind of systems, we consider the following quadratic cost functional
\begin{equation}
    J(u) = \int_0^T c(x_u(t),u(t))\, dt,
\end{equation}
where $c:\bbR^n\times \bbR^m \to \bbR$ is a quadratic form. That is,
\begin{equation}
    c(x,u) = \frac12 u^\top Pu + u^\top Qx + \frac12 x^\top R x,
    \qquad P\in \sym(\bbR^{m}), \, Q \in \bbR^{m\times d},\, R\in \sym(\bbR^d).
\end{equation}

The first question to be answered is the existence of solutions to the corresponding linear-quadratic (LQ) optimal control problem:
\begin{equation}
   \label{eq:ocp-linear}
   \begin{cases}
    \dot x = A x + Bu \\
    x(0)=x_0 \\
    x(T) = x_1 \\
    J(u) = \int_0^T c(x_u(t),u(t))\, dt \rightarrow \min.
   \end{cases} 
\end{equation}

\thm[ocp-existence-linear]{Existence of solution to \eqref{eq:ocp-linear}}{
    An optimal solution for \eqref{eq:ocp-linear} exists if and only if 
    \begin{equation}
        J(u) \ge 0 \qquad \forall u \in \Omega_{0,0,T}.
    \end{equation}
}

\begin{proof}
    The idea is to use controls in $\tilde u \in \Omega_{0,0,T}$ as variations to test the optimality of $u\in \Omega_{x_0,x_1,T}$.
    Indeed, by linearity of the control system, the control $u_\lambda = u + \lambda \tilde u$ belongs to $\Omega_{x_0,x_1,T}$ for any $\lambda\in \bbR$, i.e., it steers the system from $x_0$ to $x_1$ in time $T$.
    Indeed, by the variation of constants formula \eqref{eq:duhamel-formula} we have
    \begin{equation}
        \End_{x_0,T}(u_\lambda) = e^{TA}x_0 + \int_0^T e^{(T-s)A}B(u + \lambda \tilde u(s))\, ds = x_1 + \lambda \underbrace{\int_0^T e^{(T-s)A}B\tilde u(s)\, ds}_{\End_{0,T}(\tilde u)=0} = x_1.
    \end{equation}
    In particular, letting $x$ (resp.~$\tilde x$, and $x_\lambda$) be the trajectory corresponding to $u$ (resp.~$\tilde u$, and $u_\lambda$), it then follows that $x_\lambda = x + \lambda \tilde x$.
    Then, by the expression of $c(x,u)$, we have
    \begin{equation}
        \label{eq:aaaa}
        c(x_\lambda,u_\lambda)
        = \lambda^2 c(x_0, \tilde u) + \lambda \left[\frac12\tilde u^\top P u + \tilde u^\top Q x + u^\top Q x_0 + x_0^\top Rx \right] + c(x, u),
        \qquad \forall t\in [0,T]
    \end{equation}
    
    Observe that $u$ is an optimal control if and only if $J(u_\lambda)\ge J(u)$ for all $\lambda\in \bbR$ and $\tilde u\in \Omega(0,0,T)$. 
    Indeed, for any competitor $v\in \Omega(x_0,x_1,T)$ we can write $v = u + \tilde u$ for some $\tilde u\in \Omega(0,0,T)$, and then $J(v) = J(u_1)\ge J(u)$.
% 
    Hence, integrating \eqref{eq:aaaa} over $[0,T]$, the optimality of $u$ is equivalent to 
    \begin{equation}
       \lambda^2 \underbrace{\int_0^T c(x_0, \tilde u)\, ds}_{=J(\tilde u)} + \lambda \int_0^T \left[\frac12\tilde u^\top P u^\star + \tilde u^\top Q x^\star + (u^\star)^\top Q x_0 + x_0^\top Rx^\star \right] \, ds \ge 0, 
       \qquad \forall \lambda\in \bbR, \, \tilde u\in \Omega(0,0,T).
    \end{equation}
    This is clearly equivalent to the fact that $J(\tilde u)\ge 0$ for all $\tilde u\in \Omega(0,0,T)$.
\end{proof}

We henceforth consider the following assumptions.

\ass[]{}{
    \begin{itemize}
        \item The pair $(A,B)$ satisfies the Kalman rank condition.
        \item There exists $T_{\max}>0$ such that the functional $J$ is non-negative on $\Omega_{0,0,T_{\max}}$.
        \item The system is \emph{dissipative}, i.e., for any $T\in (0,T_{\max}]$ there exists a control $u\in \Omega_{0,0,T}$ such that $J(u)>0$.
    \end{itemize}
}

The first assumption ensures that the system is controllable, and thus that the optimal control problem \eqref{eq:ocp-linear} can have a solution. 
By Theorem~\ref{th:ocp-existence-linear}, the second assumption guarantees the existence of a solution to \eqref{eq:ocp-linear} for any $T<T_{\max}$ and any $x_0,x_1\in \bbR^d$.
The third assumption is a technical condition, and it guarantees the uniqueness of the solution.

An important consequence of the third assumption is the following.

\prop[dissipativity]{}{
    Let $u\in \Omega_{x_0,x_1,T}$. Then, for any $\varepsilon>0$ there exists a control $u_\varepsilon\in \Omega_{x_0,x_1,T}$ such that 
    \begin{equation}
        J(u_\varepsilon)= J(u)+\varepsilon.
    \end{equation}
}

\begin{proof}
    Let $\bar u \in \Omega_{0,0,T}$ be such that $J(\bar u)>0$, which exists by the dissipativity assumption.
    Then, for any $\lambda\in\bbR$ the control $u_\lambda = u+\lambda\bar u$ belongs to $\Omega_{x_0,x_1,T}$.
    Then, $\lambda\mapsto J(u_\lambda)$ is continuous and strictly increasing, with $J(u_0)=J(u)$ and $\lim_{\lambda\to +\infty} J(u_\lambda) = +\infty$.
    The conclusion follows by the intermediate value theorem.
\end{proof}

Observe that the second assumption is always satisfied if $P$ is non-negative definite (i.e., $c(x,u)$ is strictly convex in $u$ for any fixed $x$).
It turns out that this is actually necessary.

\prop[P-semi-def]{}{
    We have that $P\in \sym_{\ge0}(\bbR^m)$.
}

\begin{proof}
    Assume by contradiction that there exists a splitting $E_1\oplus E_2 = \bbR^m$ such that $P$ is negative definite on $E_2$.
    Then, there exists $K>0$ such that $u^\top P u \le -K \|u\|_2^2$ for all $u\in E_2$.
    This implies that 
    \begin{equation}
        c(x,u) \le -\frac{K}2 \|u\|_2^2 + \|u\|_2\|Q\|\|x\|_2 + \frac12 \|R\|\|x\|_2^2 \qquad \forall (x,u)\in \bbR^d\times E_2.
    \end{equation}
    As a consequence, there exists $T_0,c>0$ such that for any $T<T_0$ and any control $u\in L^\infty([0,T],E_2)$, with $u\in \Omega_{0,0,T}$ we have $J(u)\le -c\|u\|_{L^2}^2<0$.
\end{proof}

\subsection{Pontryagin Maximum Principle for LQ problems}

Let us consider the extended system on $(x,\bar x)\in \bbR^d\times \bbR$, given by 
\begin{equation}
    \begin{cases}
        \dot x = Ax + B u,\\
        \dot{\bar x} = c(x,u).
    \end{cases}
    \qquad 
    (x(0),\bar x(0)) = (x_0,0).
\end{equation}
Denote the corresponding reachable set at time $T>0$ by $\reach^{\text{ext}}_{x_0,T}$.
We then have the following, to be compared with the geometric interpretation for optimality, presented in Section~\ref{sec:geometric-interpretation}.

\thm[]{Optimality and extended system}{
    Assume that the control $u^\star\in \Omega_{x_0,x_1,T}$ is an optimal solution to \eqref{eq:ocp-linear}. 
    Then,
    \begin{equation}
        \label{eq:extended-optimality}
        (x_1, J(u^\star)) \in \partial \reach^{\text{ext}}_{x_0,T}.
    \end{equation}
    Conversely, every point $(x_1,\bar J)\in \partial \reach^{\text{ext}}_{x_0,T}$ corresponds to an optimal solution $u^\star\in \Omega_{x_0,x_1,T}$ with $J(u^\star) = \bar J$.
}

\begin{proof}
    The key observation is that any point $(x_,\bar J)\in \reach^{\text{ext}}_{x_0,T}$ is of the form $(x_u(T), J(u))$ for some $u\in \mathcal U_{x_0,T}$.

    Then, if $u^\star$ is optimal, the extended terminal point $(x_1,J(u^\star))$ must be the lowest point of the line $\{x_1\}\times \bbR$ to belong to $\reach^{\text{ext}}_{x_0,T}$. In particular, this implies \eqref{eq:extended-optimality}.
    
    Conversely, assume that $(x_1,\bar J(\bar u))\in \partial \reach^{\text{ext}}_{x_0,T}$ for some control $\bar u\in \Omega_{x_0,x_1,T}$, but that $v$ is not optimal for \eqref{eq:ocp-linear}.
    Then, there exists a control $v\in \Omega_{x_0,x_1,T}$ such that $J(v)=J(\bar u)-\varepsilon$ for a certain $\varepsilon>0$.
% 
    Given $\delta>0$, let $V_\delta = \{ u \in L^\infty([0,T],\bbR^m)\mid \|u-v\|_\infty<\delta\}$. 
    % Then, the map 
    % \begin{equation}
    %     F:u \in V_\delta \mapsto (x_u(T),J(u)) \in \bbR^{n+1},
    % \end{equation} 
    % is a continous map. 
    Since the system is controllable (see Corollary~\ref{th:local-contr-with-control-constraint}), $\End_{x_0,T}$ is an open mapping, and thus $\End_{x_0,T}(V_\delta)$ covers a neighborhood of $x_1$ in $\bbR^d$.
    This implies that there exists $\delta>0$ sufficiently small such that 
    \begin{equation}
        J(u) \le J(v)+\frac\varepsilon2 = J(\bar u)-\frac{\varepsilon}2, \qquad \forall u\in V_\delta.
    \end{equation}
    In particular, by Proposition~\ref{prop:dissipativity}, for any $y\in \End_{x_0,T}(V_\delta)$ and any $\alpha\in [J(\bar u)-\frac{\varepsilon}2,J(\bar u)+\frac{\varepsilon}2]$ there exists $u_\alpha\in \Omega_{x_0,x_1,T}$ such that $J(u_\eta) = J(\bar u)-\frac{\varepsilon}2 + \eta$. Namely,
    \begin{equation}
       W:=\left[J(\bar u)-\frac{\varepsilon}2,J(\bar u)+\frac{\varepsilon}2\right] \times  \End_{x_0,T}(V_\delta) \subset \reach^{\text{ext}}_{x_0,T}.
    \end{equation}
    Since $W$ is a neighborhood of $(x_1,J(\bar u))$, this contradicts the fact that $(x_1,J(\bar u))\in \partial \reach^{\text{ext}}_{x_0,T}$.
\end{proof}

\ex[]{Convex LQ systems}{
    The LQ optimal control problem \eqref{eq:ocp-linear} is \emph{convex} if $c:\bbR^d\times\bbR^m\to \bbR$ is a convex function. This is the case, e.g., if $P\in \sym_{>0}(\bbR^m)$, $R\in \sym_{\ge0}(\bbR^d)$, and $Q=0$.

    An LQ optimal control problem always satisfies $c(x,u)\ge 0$. Moreover, in this case the reachable set $\reach^{\text{ext}}_{x_0,T}$ is convex.
}


\thm[]{Pontryagin Maximum Principle for LQ problems}{
    Let $u^\star\in \Omega_{x_0,x_1,T}$ be an optimal solution to \eqref{eq:ocp-linear}, and let $x^\star$ be the corresponding trajectory.
    Then, there exists a nontrivial Lipschitz function $p:[0,T]\to \bbR^d$ such that 
    \begin{equation}
        \begin{cases}
            \dot x^\star = Ax^\star + Bu^\star, \\
            \dot p = -A^\top p + Rx^\star + Q^\top u^\star,
        \end{cases}
        \qquad
        \text{and}\qquad
        u^\star(t) = \arg\max_{v\in \bbR^m} H(x^\star(t),p(t),v),
    \end{equation}
    where the Hamiltonian $H:\bbR^d\times \bbR^d\times \bbR^m\to \bbR$ is given by
    \begin{equation}
        H(x,p,u) =p^\top (Ax + Bu) -c(x,u).
    \end{equation}
}

\begin{proof}
    We have that $(x_1,J(u^\star))\in \partial \reach^{\text{ext}}_{x_0,T}$. 
    Let us consider variations of the form $u_\lambda = u^\star + \lambda \tilde u$, where $\tilde u\in L^\infty([0,T],\bbR^m)$.
    Then, by the same argument used in the proof of Theorem~\ref{th:ocp-existence-linear}, we have that $x_\lambda = x^\star + \lambda \tilde x$, where $\tilde x$ is the trajectory corresponding to $\tilde u$ with initial condition $\tilde x(0)=0$. Observe that $x_\lambda(T)\neq x_1$ in general and that, as in \eqref{eq:aaaa}, 
    \begin{equation}
        \label{eq:aaaa2}
        J(u_\lambda) = J(u^\star) + \lambda \int_0^T \left[ \frac{\partial}{\partial u} c(x^\star, u^\star) \,\tilde u + \frac{\partial}{\partial x}c(x^\star, u^\star) \, \tilde x  \right] \, dt + \lambda^2 J(\tilde u).
    \end{equation}

    Consider the map $F:L^\infty([0,T],\bbR^m) \to \bbR^{d+1}$ given by
    \begin{equation}
        F(u) = (x_u(T), J(u)).
    \end{equation}
    Then, $F(u_\lambda) = (x_\lambda(T), J(u_\lambda))$ belongs to $\reach^{\text{ext}}_{x_0,T}$ for all $\lambda\in \bbR$. 
    We compute its directional derivative $L(\tilde u):=DF_{u^\star}(\tilde u) 
        = \lim_{\lambda\to 0} \frac{F(u_\lambda)-F(u^\star)}{\lambda}$ at $u^\star$ in the direction $\tilde u$, obtaining
    \begin{equation}
        L(\tilde u)
        = \left( \tilde x(T), \int_0^T \left[ \frac{\partial}{\partial u} c(x^\star, u^\star) \, \tilde u + \frac{\partial}{\partial x}c(x^\star, u^\star) \, \tilde x  \right] \, dt   \right).
    \end{equation}

    The key observation is then the following: there exists a linear form $p_T:\bbR^d\to \bbR$ such that 
    \begin{equation}
        \label{eq:L-der}
        L(\tilde u) = (\tilde x(T),p_T(\tilde x(T))), \qquad \forall \tilde u\in L^\infty([0,T],\bbR^m).
    \end{equation}
    Indeed, $L$ is a linear map from the infinite-dimensional space $L^\infty([0,T],\bbR^m)$ to the finite-dimensional space $\bbR^{d+1}$, and thus $\operatorname{ran} L$ is a linear subspace of $\bbR^{d+1}$ of dimension at most $d+1$. But, on one hand, controllability implies that $\operatorname{ran} L$ contains the subspace $\bbR^d\times \{0\}$, which has dimension $d$. On the other hand, if $\operatorname{ran} L = \bbR^{d+1}$ then for any $\alpha>0$ there would exists $v$ such that $L(v) = (0,-\alpha)$. 
    In particular, the corresponding trajectory $y$ satisfies $y(T)=0$ and hence $x_\lambda (T) = x^\star(T) +\lambda y(T) = x_1$. 
    As a consequence, \eqref{eq:aaaa2} yields 
    \begin{equation}
    J(u_\lambda) = J(u^\star)-\lambda \alpha+ \lambda^2 J(v), \qquad \forall \lambda\in\bbR 
    \implies J(u_\lambda) < J(u^\star), \qquad \lambda \ll 1.
    \end{equation} 
    This contradicts the optimality of $u^\star$. Hence, $\operatorname{ran} L$ has dimension exactly $d$, and thus it is the graph of a linear form $p_T:\bbR^d\to \bbR$.

    To complete the proof, we need to show that $p_T$ is of the form $p_T(\tilde x(T)) = p(T)^\top \tilde x(T)$ for some absolutely continuous function $p:[0,T]\to \bbR^d$ satisfying the adjoint equation $\dot p = -A^\top p + Rx^\star$.
    \begin{equation}
        \label{eq:adjoint-eq-proof}
        \dot p =-A^\top p + Rx^\star + Q^\top u^\star =  -A^\top p + \frac{\partial}{\partial x}c(x^\star, u^\star).
    \end{equation}
    Let us consider a solution to the above with terminal condition $p(T)=p_T$.
    Then, recalling that $\tilde x = A\tilde x + B \tilde u$ and that $\tilde x(0)=0$, by \eqref{eq:L-der} we obtain
    \begin{equation}
       \int_0^T \left[ \frac{\partial}{\partial u} c(x^\star, u^\star) \, \tilde u + \frac{\partial}{\partial x}c(x^\star, u^\star) \, \tilde x  \right] \, dt 
       = p(T)^\top (x(T)) 
       = \int_0^T \frac{d}{dt} \left[p^\top x\right]\, dt 
       = \int_0^T \left[ \dot p^\top x + p^\top (Ax + Bu) \right]\, dt.
    \end{equation}
    Replacing \eqref{eq:adjoint-eq-proof} in the above, we obtain 
    \begin{equation}
        \int_0^T \left[\frac{\partial}{\partial u} c(x^\star, u^\star) - B^\top p \right]\, \tilde u = 0, \qquad \forall \tilde u\in L^\infty([0,T],\bbR^m). 
    \end{equation} 
    That is, 
    \begin{equation}
       \frac{\partial}{\partial u} c(x^\star, u^\star) - B^\top p = 0 \qquad \text{for a.e.\ } t\in [0,T],  
    \end{equation}
    which is equivalent to the maximization condition $u^\star(t) = \arg\max_{v\in \bbR^m} H(x^\star(t),p(t),v)$, since
    \begin{equation}
        \frac{\partial}{\partial u} H(x,p,u) = \frac{\partial}{\partial u} c(x,u) - B^\top p,
    \end{equation}
    and $H$ is concave in $u$ for any fixed $(x,p)$ due to the fact that $P\in \sym_{\ge0}(\bbR^m)$ by Proposition~\ref{prop:P-semi-def}.
\end{proof}

\subsection{Lagrangian interpretation of PMP for LQ problems}

Let $\Lip([0,T], \bbR^d)$ be the space of Lipschitz functions $x:[0,T]\to \bbR^d$ endowed with the norm $\|x\|_{\Lip}=\|x\|_\infty + L_x$, where $L_x$ denotes the Lipschitz constant of $x$. 
Let us consider the extended cost functional 
\begin{equation}
    J: \Lip([0,T],\bbR^d) \times L^\infty([0,T],\bbR^m) \to \bbR, \qquad
    J(x,u) = \int_0^T c(x(t),u(t))\, dt.
\end{equation}
Then, the optimal control problem \eqref{eq:ocp-linear} can be rephrased as the following infinite-dimensional optimization problem with dynamical constraints:
\begin{equation}
    \min_{(x,u) \in \Lip([0,T],\bbR^d) \times L^\infty([0,T],\bbR^m)} J(x,u) \qquad\text{subject to}\qquad \dot x = Ax + Bu,\, x(0)=x_0,\, x(T)=x_1.
\end{equation}
Assume for simplicity that $Q=0$, so that $c(x,u)=\frac12\left(u^\top P u + x^\top Rx\right)$.
Following the ideas presented in Chapter~\ref{chp:optimization-problems}, we then introduce the Lagrangian $\mathcal L:\Lip([0,T],\bbR^d) \times L^\infty([0,T],\bbR^m) \times \Lip([0,T],\bbR^d) \to \bbR$ given by
\begin{equation}
    \begin{split}
        \mathcal L (x,u, p)
         & =  \frac12\int_0^T \left(u^\top P u + x^\top Rx\right)\,dt + \int_0^T p^\top \left(\dot x - Ax-Bu\right)\, dt                                \\
         & =  \frac12\int_0^T \left(u^\top P u + x^\top Rx\right)\,dt - \int_0^T p^\top \left(Ax+Bu-(x_1-x_0)\right)\, dt -\int_0^T \dot p^\top x\, dt. \\
    \end{split}
    \end{equation}
Here $p\in \Lip([0,T],\bbR^d)$ is the Lagrange multiplier associated with the dynamical constraint $\dot x = Ax + Bu$, and in the last equality we have integrated by parts the term $\int_0^T p^\top \dot x\, dt$ and used the boundary conditions $x(0)=x_0$ and $x(T)=x_1$.

An optimal solution $(x^\star, u^\star)$ should then satisfy the stationarity condition 
\begin{equation}
    \frac{\partial}{\partial (x,u)} \mathcal L(x^\star, u^\star, p) = 0, \qquad \text{for some } p \in\Lip([0,T],\bbR^d).
\end{equation}
But this yields:
\begin{itemize}
    \item Variation w.r.t.~$u$:
    \begin{equation}
        0= \frac{\partial}{\partial u} \mathcal L(x^\star, u^\star, p) = Pu + B^\top p.
    \end{equation}
    This yields the control law $u^\star = - P^{-1} B^\top p$.
    \item Variation w.r.t.~$x$: 
    % in order to do this, we need to integrate by parts the term $\int_0^T p^\top \dot x\, dt$:
    % \begin{equation}
    %     \int_0^T p^\top \dot x\, dt = \left[ p^\top x \right]_0^T - \int_0^T \dot p^\top x\, dt = p^\top (x_1 - x_0) - \int_0^T \dot p^\top x\, dt.
    % \end{equation}
    % Then, we obtain 
    \begin{equation}
        0 = \frac{\partial}{\partial x} \mathcal L(x^\star, u^\star, p) = R x - \dot p - A^\top p.
    \end{equation}
    This yields the adjoint equation $\dot p = -A^\top  p + Rx$.

\end{itemize}